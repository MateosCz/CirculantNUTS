{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ki5fKrZBuNL",
    "outputId": "69eae75e-bc10-4509-8eea-d677361f355d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpyro in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: jax>=0.4 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.4.10)\n",
      "Requirement already satisfied: jaxlib>=0.4 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.4.10+cuda11.cudnn86)\n",
      "Requirement already satisfied: multipledispatch in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.6.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (4.65.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (0.1.0)\n",
      "Requirement already satisfied: opt-einsum in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (1.10.1)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from multipledispatch->numpyro) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jax.numpy.fft import irfft, rfft, fft, ifft\n",
    "\n",
    "from jax import grad, jit, vmap\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import jax\n",
    "\n",
    "!pip install numpyro\n",
    "import numpyro\n",
    "from numpyro import handlers\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "import numpyro.contrib.module as module\n",
    "\n",
    "!pip install -q flax\n",
    "from flax import linen as nn\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "\n",
    "matplotlib.use(\"Agg\")  # noqa: E402\n",
    "np.random.seed(0)\n",
    "key = numpyro.prng_key()\n",
    "numpyro.set_host_device_count(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices(backend='gpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Hu9LZWJPCGh1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numpy_collate(batch):\n",
    "  if isinstance(batch[0], np.ndarray):\n",
    "    return np.stack(batch)\n",
    "  elif isinstance(batch[0], (tuple,list)):\n",
    "    transposed = zip(*batch)\n",
    "    return [numpy_collate(samples) for samples in transposed]\n",
    "  else:\n",
    "    return np.array(batch)\n",
    "\n",
    "\n",
    "class NumpyLoader(torch.utils.data.DataLoader):\n",
    "  def __init__(self, dataset, batch_size=1,\n",
    "                shuffle=False, sampler=None,\n",
    "                batch_sampler=None, num_workers=0,\n",
    "                pin_memory=False, drop_last=False,\n",
    "                timeout=0, worker_init_fn=None):\n",
    "    super(self.__class__, self).__init__(dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn)\n",
    "\n",
    "class FlattenAndCast(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.ravel(np.array(pic, dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KKqyhf6UCIFw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mnist(n, m):\n",
    "    \"\"\"\n",
    "    Download MNIST and return train and evaluation sets.\n",
    "    \"\"\"\n",
    "    mnist = datasets.MNIST('data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=FlattenAndCast())\n",
    "    mnist = list(mnist)\n",
    "    # One batch with all of mnist\n",
    "    train_loader = NumpyLoader(mnist, batch_size=len(mnist), num_workers=0)\n",
    "    x, y = list(train_loader)[0]\n",
    "    # Normalize\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    # Train and test set\n",
    "    train_x, train_y = x[0:n], y[0:n]\n",
    "    val_x, val_y = x[n:n+m], y[n:n+m]\n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CvNmAUrFCKOi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class flax_CNN(nn.Module):\n",
    "    @nn.compact   \n",
    "    def __call__(self, x):\n",
    "        #print(x.shape)\n",
    "        x_length = x.shape[0]\n",
    "        x = nn.Conv(features = 8, kernel_size = (5,5),strides = (1,1), \n",
    "                   padding = (2,2), \n",
    "                   use_bias= False)(x)\n",
    "        print(x.shape)\n",
    "        x = nn.max_pool(x,window_shape=(2,2),strides = (2,2))\n",
    "        all_len = len(x.flatten())\n",
    "        x = x.reshape((x_length, int((all_len/x_length))))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfmvSjGQCMNE",
    "outputId": "42e353bb-e1e2-43cb-e749-caf48374b4cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "_x, _y, _xv, _yv = get_mnist(50000,10000)\n",
    "\n",
    "# Training\n",
    "N=1000 \n",
    "# Test\n",
    "M=300\n",
    "\n",
    "# Get the training and test data from the MNIST global variables\n",
    "x, y, xv, yv = _x[0:N], _y[0:N], _xv[N:N+M], _yv[N:N+M]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ip2VF9VjCNUp",
    "outputId": "8d33bd52-dc07-4201-827b-5285c1ca5f59",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 8)\n",
      "\n",
      "\u001b[3m                                flax_CNN Summary                                \u001b[0m\n",
      "┏━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams          \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│        │ flax_CNN │ \u001b[2mfloat32\u001b[0m[1000,28,… │ \u001b[2mfloat32\u001b[0m[1000,156… │                  │\n",
      "├────────┼──────────┼───────────────────┼───────────────────┼──────────────────┤\n",
      "│ Conv_0 │ Conv     │ \u001b[2mfloat32\u001b[0m[1000,28,… │ \u001b[2mfloat32\u001b[0m[1000,28,… │ kernel:          │\n",
      "│        │          │                   │                   │ \u001b[2mfloat32\u001b[0m[5,5,1,8] │\n",
      "│        │          │                   │                   │                  │\n",
      "│        │          │                   │                   │ \u001b[1m200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m      │\n",
      "├────────┼──────────┼───────────────────┼───────────────────┼──────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\n",
      "└────────┴──────────┴───────────────────┴───────────────────┴──────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m\u001b[1m                          \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim1 = 128\n",
    "dim2 = 32\n",
    "key = random.PRNGKey(0)\n",
    "conv = flax_CNN() #from (200,28,28) to (200, 1568)\n",
    "\n",
    "rng_key = random.PRNGKey(1)\n",
    "\n",
    "print(conv.tabulate(jax.random.PRNGKey(0), x.reshape((-1,28,28,1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "B9ZwnElxCP2Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def circ_matmul(x, w, output_size):\n",
    "    # xw = fft(fft(w)*ifft(x)).real\n",
    "    # Note the use of the n argument to get right output shape\n",
    "    xw = irfft(jnp.conj(rfft(w)) * rfft(x), output_size)\n",
    "    return xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qmk0rGrVCQ90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the non-linearity we use in our neural network\n",
    "def nonlin(x):\n",
    "    return jnp.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def circ_conv(x, w,input_size, output_size):\n",
    "    out = irfft(jnp.conj(rfft(w)) * rfft(x), n=output_size)\n",
    "    print(out.shape)\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1586)\n",
      "[[8.829421 8.829421 8.829421 ... 8.829421 8.829421 8.829421]]\n"
     ]
    }
   ],
   "source": [
    "out = circ_conv(x[0], jnp.ones([1, 784]), 784, 1586)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "x1N4sDqtCSvJ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "# TODO: add numlayer parameter, add whether has cnn parameter, add whether use circulant multiply, add cnn parameters.calculate dimensions. \n",
    "print(x.shape)\n",
    "def model_circulant_weight(x, y=None, dim1 = dim1, dim2 = dim2):\n",
    "    w1 = numpyro.sample(\"w1\", dist.Normal(0,1).expand([28*28*2]).to_event(1))\n",
    "    b1 = numpyro.sample(\"b1\", dist.Normal(0,1).expand([dim1]).to_event(1))\n",
    "\n",
    "    w2 = numpyro.sample(\"w2\", dist.Normal(0,1).expand([dim1]).to_event(1))\n",
    "    b2 = numpyro.sample(\"b2\", dist.Normal(0,1).expand([dim2]).to_event(1))\n",
    "\n",
    "\n",
    "    w3 = numpyro.sample(\"w3\", dist.Normal(0,1).expand([dim2,10]).to_event(2))\n",
    "    b3 = numpyro.sample(\"b3\", dist.Normal(0,1).expand([10]).to_event(1))    \n",
    "\n",
    "    # Convolution\n",
    "    # conv_numpyro = module.random_flax_module(\"conv\", conv, dist.Normal(0, 1), input_shape=((x.shape[0],28,28,1)))\n",
    "    # cx = nonlin(conv_numpyro(x.reshape((-1,28,28,1))))\n",
    "    \n",
    "    w_conv = numpyro.sample(\"w_conv\", dist.Normal(0,1).expand([28*28]))\n",
    "    cx = nonlin(circ_matmul(x, w_conv, 28*28*2))\n",
    "    #print(shape)\n",
    "\n",
    "    # Layer 1: dim1\n",
    "    \n",
    "    h1 = circ_matmul(cx, w1, dim1)\n",
    "    h1 = nonlin(h1[:, 0:dim1] + b1)\n",
    "    # Layer 2: dim2\n",
    "    h2 = circ_matmul(h1, w2, dim2)\n",
    "    h2 = nonlin(h2[:, 0:dim2] + b2)\n",
    "\n",
    "    # Layer 3: dim=10 (logits)\n",
    "    h3 = jnp.matmul(h2,w3) + b3\n",
    "    # Register the logits for easy prediction\n",
    "    numpyro.deterministic(\"logits\", h3)\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"labels\", x.shape[0]):\n",
    "        y_obs = numpyro.sample(\"y_obs\", dist.CategoricalLogits(logits=h3), \n",
    "                               obs=y, rng_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0b5cQ8cVKasn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_full_weight(x, y=None):\n",
    "  w1_full = numpyro.sample(\"w1_full\", dist.Normal(0,1).expand([2*28*28,dim1]).to_event(1)) #weight matrix dimension: (indim(1568), h1dim(dim1 128))\n",
    "  b1_full = numpyro.sample(\"b1_full\", dist.Normal(0,1).expand([dim1]).to_event(1)) # bias dimension: (128,)\n",
    "\n",
    "  w2_full = numpyro.sample(\"w2_full\", dist.Normal(0,1).expand([dim1,dim2]).to_event(1)) #weight matrix dimension: (h1dim(dim1), h2dim(dim2))\n",
    "  b2_full = numpyro.sample(\"b2_full\", dist.Normal(0,1).expand([dim2]).to_event(1)) # bias dimension: (dim2,)\n",
    "\n",
    "  w3_full = numpyro.sample(\"w3_full\", dist.Normal(0,1).expand([dim2,10]).to_event(2)) #weight matrix dimension: (h2dim(dim2), outdim(10))\n",
    "  b3_full = numpyro.sample(\"b3_full\", dist.Normal(0,1).expand([10]).to_event(1)) # bias dimension: (outdim(10))  \n",
    "\n",
    "  conv_numpyro = module.random_flax_module(\"conv_full\", conv, dist.Normal(0, 1), input_shape=((x.shape[0],28,28,1)))\n",
    "  cx = nonlin(conv_numpyro(x.reshape((-1,28,28,1))))\n",
    "\n",
    "\n",
    "  h1 = nonlin(jnp.matmul(cx,w1_full) + b1_full)\n",
    "\n",
    "  h2 = nonlin(jnp.matmul(h1,w2_full) + b2_full)\n",
    "\n",
    "  h3 = jnp.matmul(h2,w3_full) + b3_full\n",
    "\n",
    "  # Register the logits for easy prediction\n",
    "  numpyro.deterministic(\"logits_full\", h3)\n",
    "\n",
    "\n",
    "  # Likelihood\n",
    "  with numpyro.plate(\"labels_full\", x.shape[0]):\n",
    "      y_obs_f = numpyro.sample(\"y_obs_full\", dist.CategoricalLogits(logits = h3), obs = y, rng_key=key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The point estimate model common neural network\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=8,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "                bias = False\n",
    "            )\n",
    "        # Lift to Pyro\n",
    "        self.maxp = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Sequential(torch.nn.Linear(in_features=2*28*28, out_features=dim1), torch.nn.Tanh(), \n",
    "                                      torch.nn.Linear(in_features= dim1, out_features=dim2), torch.nn.Tanh(), \n",
    "                                      torch.nn.Linear(in_features = dim2, out_features=10), torch.nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        cx = self.conv(x)\n",
    "        px = self.maxp(cx)\n",
    "        fx = torch.flatten(px, 1)\n",
    "        x_output = self.fc(fx)\n",
    "        return x_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxaB3q9g-e0N",
    "outputId": "c44fe55c-d96d-42b9-fbb6-24b3ec331a2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243/3640374796.py:8: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  mcmc = MCMC(kernel,\n",
      "sample: 100%|██████████| 150/150 [05:04<00:00,  2.03s/it, 1023 steps of size 1.42e-03. acc. prob=0.94]\n",
      "sample: 100%|██████████| 150/150 [05:02<00:00,  2.02s/it, 1023 steps of size 1.07e-03. acc. prob=0.98]\n"
     ]
    }
   ],
   "source": [
    "# train the circulant matrix model\n",
    "%time\n",
    "kernel = NUTS(model_circulant_weight,\n",
    "              target_accept_prob = 0.8,\n",
    "              max_tree_depth = 10\n",
    "              )\n",
    "\n",
    "mcmc = MCMC(kernel,\n",
    "            num_samples = 100,\n",
    "            num_warmup = 50,\n",
    "            num_chains = 2,\n",
    "            progress_bar = True)\n",
    "\n",
    "mcmc.run(random.PRNGKey(0), x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKsFyO0kCUNg",
    "outputId": "5d3ba65a-016d-4747-af7c-b123fc123736"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243/4160828757.py:7: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  mcmc_1 = MCMC(kernel_1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 8)\n",
      "(1000, 28, 28, 8)\n",
      "(1000, 28, 28, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 150/150 [07:36<00:00,  3.04s/it, 1023 steps of size 2.68e-03. acc. prob=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 8)\n",
      "(1000, 28, 28, 8)\n",
      "(1000, 28, 28, 8)\n",
      "(1000, 28, 28, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 150/150 [07:33<00:00,  3.02s/it, 1023 steps of size 2.31e-03. acc. prob=0.92]\n"
     ]
    }
   ],
   "source": [
    "# Train the full weight matrix model\n",
    "kernel_1 = NUTS(model_full_weight,\n",
    "              target_accept_prob = 0.8,\n",
    "              max_tree_depth = 10\n",
    "              )\n",
    "\n",
    "mcmc_1 = MCMC(kernel_1,\n",
    "            num_samples = 100,\n",
    "            num_warmup = 50,\n",
    "            num_chains = 2,\n",
    "            progress_bar = True)\n",
    "\n",
    "mcmc_1.run(random.PRNGKey(1), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n",
      "Epoch: 10, Average Loss: 0.8373497306108475\n",
      "Epoch: 20, Average Loss: 0.8354415633082389\n",
      "Epoch: 30, Average Loss: 0.8034206417202949\n",
      "Epoch: 40, Average Loss: 0.8174283702969551\n",
      "Epoch: 50, Average Loss: 0.8096831457614899\n",
      "Epoch: 60, Average Loss: 0.8151490816473961\n",
      "Epoch: 70, Average Loss: 0.7996587716937065\n",
      "Epoch: 80, Average Loss: 0.8067343647480011\n",
      "Epoch: 90, Average Loss: 0.8071548728346825\n",
      "Epoch: 100, Average Loss: 0.8047575291991234\n"
     ]
    }
   ],
   "source": [
    "# Train the point estimation mmodel\n",
    "\n",
    "def get_mnist_torch(n, m):\n",
    "    \"\"\"\n",
    "    Download MNIST and return train and evaluation sets.\n",
    "    \"\"\"\n",
    "    img_to_tensor = transforms.ToTensor()\n",
    "    mnist = datasets.MNIST('data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=img_to_tensor)\n",
    "    mnist = list(mnist)\n",
    "    # One batch with all of mnist\n",
    "    train_loader = torch.utils.data.DataLoader(mnist,\n",
    "        batch_size=len(mnist),\n",
    "        shuffle=True)\n",
    "    # x = images tensor, y = labels tensor \n",
    "    x, y = list(train_loader)[0]\n",
    "    # Flatten images\n",
    "    x = x.view(-1, 28*28)\n",
    "    # Normalize\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    # Train and test set\n",
    "    train_x, train_y = x[0:n], y[0:n]\n",
    "    val_x, val_y = x[n:n+m], y[n:n+m]\n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "\n",
    "def train_point_estimation(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    model.cuda()\n",
    "    loss_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for _, (data, label) in enumerate(dataloader):\n",
    "\n",
    "            data = data.cuda()\n",
    "            labels = label.cuda()\n",
    "            model.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        # Print the average loss at every epoch\n",
    "        average_loss = epoch_loss / (len(dataloader))\n",
    "        loss_list.append(average_loss)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Average Loss: {average_loss}')\n",
    "    return loss_list\n",
    "\n",
    "point_estimate_model = CNN()\n",
    "x_torch, y_torch, xv_torch, yv_torch = get_mnist_torch(N,M)\n",
    "\n",
    "x_torch = x_torch.view((-1,1,28,28))\n",
    "print(x_torch.shape)\n",
    "xv_torch = xv_torch.view((-1,1,28,28))\n",
    "\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(x_torch,y_torch)\n",
    "test_set = torch.utils.data.TensorDataset(xv_torch,yv_torch)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle = True, batch_size = 1)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = 1)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(point_estimate_model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_list_point_estimation = train_point_estimation(point_estimate_model,train_loader, criterion, optimizer, 100)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "5LlrMZnPRiVt",
    "outputId": "5400cb48-112d-4147-aa98-f639b3b4dd6a"
   },
   "outputs": [],
   "source": [
    "# get posterior and prediction of the circular weight matrix model\n",
    "\n",
    "posterior_samples = mcmc.get_samples()\n",
    "\n",
    "\n",
    "posterior_predictive_test = numpyro.infer.Predictive(model_circulant_weight, posterior_samples)(\n",
    "        jax.random.PRNGKey(3),xv)\n",
    "\n",
    "posterior_predictive_train = numpyro.infer.Predictive(model_circulant_weight, posterior_samples)(\n",
    "        jax.random.PRNGKey(3),x)\n",
    "\n",
    "prior_predictive = numpyro.infer.Predictive(model_circulant_weight, num_samples=500)(\n",
    "        jax.random.PRNGKey(3),xv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "aW437_KjCcBA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 28, 28, 8)\n",
      "(300, 28, 28, 8)\n",
      "(1000, 28, 28, 8)\n",
      "(1000, 28, 28, 8)\n",
      "(300, 28, 28, 8)\n",
      "(300, 28, 28, 8)\n"
     ]
    }
   ],
   "source": [
    "# get posterior and prediction of the full weight matrix model\n",
    "\n",
    "posterior_samples_1 = mcmc_1.get_samples()\n",
    "\n",
    "\n",
    "posterior_predictive_test_1 = numpyro.infer.Predictive(model_full_weight, posterior_samples_1)(\n",
    "        jax.random.PRNGKey(3),xv)\n",
    "\n",
    "posterior_predictive_train_1 = numpyro.infer.Predictive(model_full_weight, posterior_samples_1)(\n",
    "        jax.random.PRNGKey(3),x)\n",
    "\n",
    "prior_predictive_1 = numpyro.infer.Predictive(model_full_weight, num_samples=500)(\n",
    "        jax.random.PRNGKey(3),xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['b1', 'b2', 'b3', 'logits', 'w1', 'w2', 'w3', 'w_conv'])\n",
      "dict_keys(['b1_full', 'b2_full', 'b3_full', 'conv_full/Conv_0.kernel', 'logits_full', 'w1_full', 'w2_full', 'w3_full'])\n",
      "(200, 784)\n",
      "(200, 5, 5, 1, 8)\n",
      "(200, 1568)\n",
      "(200, 1568, 128)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(posterior_samples.keys())\n",
    "print(posterior_samples_1.keys())\n",
    "print(posterior_samples['w_conv'].shape)\n",
    "print(posterior_samples_1['conv_full/Conv_0.kernel'].shape)\n",
    "print(posterior_samples['w1'].shape)\n",
    "print(posterior_samples_1['w1_full'].shape)\n",
    "print(len(posterior_predictive_test_1.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6G-VFAvFZoFA",
    "outputId": "4198e197-74bc-437a-809a-2608d079961e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arviz in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (0.15.1)\n",
      "Requirement already satisfied: setuptools>=60.0.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (67.7.2)\n",
      "Requirement already satisfied: matplotlib>=3.2 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (1.10.1)\n",
      "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (23.1)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (2.0.1)\n",
      "Requirement already satisfied: xarray>=0.21.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (2023.5.0)\n",
      "Requirement already satisfied: h5netcdf>=1.0.2 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (4.5.0)\n",
      "Requirement already satisfied: xarray-einstats>=0.3 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (0.5.1)\n",
      "Requirement already satisfied: h5py in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from h5netcdf>=1.0.2->arviz) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (5.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from pandas>=1.3.0->arviz) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from pandas>=1.3.0->arviz) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2->arviz) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.2->arviz) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install arviz\n",
    "import arviz as az\n",
    "az.style.use(\"arviz-doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "fF-Y7a1HhiPy"
   },
   "outputs": [],
   "source": [
    "def accuracy(pred, data):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of predicted labels (integers).\n",
    "\n",
    "    pred: predictions, ndarray[sample_index, chain_index, data_index, logits]\n",
    "    data: actual data (digit), ndarray[data_index]\n",
    "\n",
    "    Prediction is taken as most common predicted value.\n",
    "    Returns accuracy (#correct/#total).\n",
    "    \"\"\"\n",
    "    n=data.shape[0]\n",
    "    correct=0\n",
    "    total=0\n",
    "    for i in range(0, n):\n",
    "        # Get most common prediction value from logits\n",
    "        pred_i=int(jnp.argmax(jnp.sum(pred[:,i,:],0)))\n",
    "        # Compare prediction with data\n",
    "        if int(data[i])==int(pred_i):\n",
    "            correct+=1.0\n",
    "        total+=1.0\n",
    "    # Return fractional accuracy\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuir-trcRt5m",
    "outputId": "ead3abba-ae8b-41e0-d077-4c6500a5bba1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages/arviz/data/base.py:221: UserWarning: More chains (200) than draws (128). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages/arviz/data/base.py:221: UserWarning: More chains (200) than draws (32). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages/arviz/data/base.py:221: UserWarning: More chains (200) than draws (10). Passed array should have shape (chains, draws, *shape)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# summary of circulant matrix model\n",
    "\n",
    "\n",
    "#summary_data_circulant = arviz.from_numpyro(posterior=mcmc, prior=prior_predictive, posterior_predictive= posterior_predictive_test )\n",
    "summary_data_circulant = az.convert_to_inference_data(posterior_samples)\n",
    "az.plot_ess(summary_data_circulant,var_names=['w1'], kind = 'evolution')\n",
    "plt.savefig(\"posterior_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuir-trcRt5m",
    "outputId": "ead3abba-ae8b-41e0-d077-4c6500a5bba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success posterior test = 0.557\n",
      "Success posterior training = 0.921\n",
      "Success prior = 0.090\n",
      "Posterior test diagnostics:\n",
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "        b1      0.10      1.09      0.13     -1.64      1.89  20719.68      0.99\n",
      "        b2      0.24      1.12      0.25     -1.58      2.09   7430.46      0.97\n",
      "        b3     -0.13      1.20     -0.04     -1.74      1.74  -9494.41      0.93\n",
      " logits[0]      0.40      4.21      0.67     -6.65      6.88  13484.60      1.02\n",
      " logits[1]      0.07      4.16      0.05     -6.87      6.72  60594.09      1.02\n",
      " logits[2]      0.27      5.07      0.28     -8.05      8.85  66709.05      1.01\n",
      " logits[3]      0.34      3.81      0.18     -5.77      6.78   7614.71      1.03\n",
      " logits[4]     -0.27      4.48     -0.33     -7.41      7.26 187372.40      1.01\n",
      " logits[5]      1.43      3.19      1.39     -3.70      6.62   3362.10      1.04\n",
      " logits[6]     -1.48      5.79     -1.19    -11.50      7.82 186262.22      1.01\n",
      " logits[7]     -0.90      5.34     -0.99     -9.96      7.55  10732.11      1.03\n",
      " logits[8]      0.86      3.43      1.00     -5.48      6.02  60154.47      1.02\n",
      " logits[9]      0.52      3.54      0.76     -5.07      6.51  27709.01      1.02\n",
      "        w1      0.03      1.13      0.04     -1.75      1.81 296437.92      1.00\n",
      "        w2     -0.06      1.11     -0.07     -1.72      1.90  26784.98      1.00\n",
      "     w3[0]      0.06      0.86      0.05     -1.38      1.37   7385.63      0.99\n",
      "     w3[1]     -0.05      0.92     -0.09     -1.71      1.31  12043.85      0.97\n",
      "     w3[2]      0.04      0.92      0.01     -1.38      1.57   5137.16      0.97\n",
      "     w3[3]      0.13      0.88      0.11     -1.25      1.49   7637.13      0.97\n",
      "     w3[4]      0.01      0.91     -0.00     -1.52      1.49   4899.05      0.99\n",
      "     w3[5]      0.12      0.78      0.06     -1.13      1.30   7171.10      0.98\n",
      "     w3[6]      0.12      1.04      0.15     -1.52      1.83   4264.36      0.98\n",
      "     w3[7]      0.05      1.09     -0.03     -1.52      1.92   6372.77      1.00\n",
      "     w3[8]      0.02      0.73     -0.00     -1.11      1.27   6972.47      1.00\n",
      "     w3[9]      0.04      0.75      0.11     -1.11      1.26   5892.34      0.98\n",
      "    w_conv     -0.04      1.14     -0.06     -1.80      1.74 159407.58      1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test set\n",
    "logits = posterior_predictive_test['logits']\n",
    "print(\"Success posterior test = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "# Accuracy on training set\n",
    "logits = posterior_predictive_train['logits']\n",
    "print(\"Success posterior training = %.3f\" % accuracy(logits, y))\n",
    "\n",
    "logits = prior_predictive['logits']\n",
    "print(\"Success prior = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "print(\"Posterior test diagnostics:\")\n",
    "numpyro.diagnostics.print_summary(posterior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP284gjyDB-E",
    "outputId": "79284346-f872-4cb6-f56c-e8c509f01ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success posterior test = 0.923\n",
      "Success posterior training = 1.000\n",
      "Success prior = 0.117\n",
      "Posterior test diagnostics:\n",
      "\n",
      "                                    mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "                       b1_full     -0.02      1.00     -0.02     -1.64      1.63  25890.54      1.00\n",
      "                       b2_full     -0.04      0.96     -0.02     -1.66      1.52   6834.92      1.00\n",
      "                       b3_full     -0.07      0.94     -0.10     -1.51      1.54   2461.68      1.01\n",
      "conv_full/Conv_0.kernel[0,0,0]     -0.33      0.96     -0.30     -1.81      1.30   7014.18      0.97\n",
      "conv_full/Conv_0.kernel[0,0,1]     -0.04      0.87     -0.06     -1.52      1.35  -7161.55      0.85\n",
      "conv_full/Conv_0.kernel[0,0,2]      0.16      1.09      0.16     -1.62      1.90   1153.89      1.24\n",
      "conv_full/Conv_0.kernel[0,0,3]     -0.34      0.84     -0.35     -1.81      0.87   3315.58      0.86\n",
      "conv_full/Conv_0.kernel[0,0,4]     -0.21      0.90     -0.22     -1.67      1.21   1251.72      1.08\n",
      "conv_full/Conv_0.kernel[0,0,5]     -0.08      0.88     -0.18     -1.38      1.36   1242.15      1.11\n",
      "conv_full/Conv_0.kernel[0,0,6]     -0.44      1.02     -0.36     -2.20      1.18   2733.51      0.96\n",
      "conv_full/Conv_0.kernel[0,0,7]     -0.27      0.96     -0.32     -1.66      1.42    580.91      1.34\n",
      "conv_full/Conv_0.kernel[1,0,0]     -0.01      0.97     -0.05     -1.62      1.65   2333.38      0.98\n",
      "conv_full/Conv_0.kernel[1,0,1]     -0.14      0.84     -0.10     -1.62      1.08   2664.88      1.05\n",
      "conv_full/Conv_0.kernel[1,0,2]      0.03      0.99      0.07     -1.54      1.63   8995.74      0.92\n",
      "conv_full/Conv_0.kernel[1,0,3]      0.02      0.91      0.04     -1.49      1.36   9673.22      0.88\n",
      "conv_full/Conv_0.kernel[1,0,4]     -0.13      0.94     -0.09     -1.84      1.28   8127.24      0.91\n",
      "conv_full/Conv_0.kernel[1,0,5]     -0.07      0.83     -0.09     -1.44      1.22   5505.63      0.91\n",
      "conv_full/Conv_0.kernel[1,0,6]     -0.08      0.82     -0.07     -1.45      1.29  -2890.04      0.86\n",
      "conv_full/Conv_0.kernel[1,0,7]     -0.29      1.02     -0.28     -1.95      1.26   1266.71      1.01\n",
      "conv_full/Conv_0.kernel[2,0,0]      0.24      1.12      0.17     -1.57      2.05    977.40      1.03\n",
      "conv_full/Conv_0.kernel[2,0,1]     -0.18      0.85     -0.15     -1.46      1.32  14592.02      0.91\n",
      "conv_full/Conv_0.kernel[2,0,2]     -0.06      0.86     -0.05     -1.36      1.36   2553.20      1.06\n",
      "conv_full/Conv_0.kernel[2,0,3]      0.20      1.03      0.13     -1.30      1.90    880.11      1.03\n",
      "conv_full/Conv_0.kernel[2,0,4]     -0.31      0.92     -0.17     -1.83      1.17   2396.17      0.96\n",
      "conv_full/Conv_0.kernel[2,0,5]     -0.08      0.87     -0.13     -1.48      1.33   2094.87      1.05\n",
      "conv_full/Conv_0.kernel[2,0,6]     -0.27      0.79     -0.27     -1.57      0.96   1845.05      1.07\n",
      "conv_full/Conv_0.kernel[2,0,7]      0.14      0.90      0.15     -1.25      1.65   1685.61      1.04\n",
      "conv_full/Conv_0.kernel[3,0,0]      0.20      0.91      0.20     -1.36      1.61   1122.42      1.05\n",
      "conv_full/Conv_0.kernel[3,0,1]      0.21      1.01      0.17     -1.47      1.84   1443.96      0.87\n",
      "conv_full/Conv_0.kernel[3,0,2]     -0.24      0.94     -0.22     -1.70      1.38  -8292.96      0.83\n",
      "conv_full/Conv_0.kernel[3,0,3]      0.00      0.90     -0.01     -1.47      1.42   4065.81      0.94\n",
      "conv_full/Conv_0.kernel[3,0,4]     -0.22      0.86     -0.17     -1.75      1.00   2888.82      0.95\n",
      "conv_full/Conv_0.kernel[3,0,5]     -0.02      0.92     -0.13     -1.42      1.52   2589.74      1.00\n",
      "conv_full/Conv_0.kernel[3,0,6]     -0.15      0.89     -0.14     -1.38      1.45  -5976.54      0.86\n",
      "conv_full/Conv_0.kernel[3,0,7]      0.00      0.89      0.02     -1.53      1.34   8517.24      0.96\n",
      "conv_full/Conv_0.kernel[4,0,0]     -0.21      0.82     -0.16     -1.45      1.03 -39314.03      0.94\n",
      "conv_full/Conv_0.kernel[4,0,1]     -0.18      1.10     -0.17     -1.84      1.77    399.35      1.47\n",
      "conv_full/Conv_0.kernel[4,0,2]     -0.27      0.83     -0.18     -1.80      0.98   8615.85      0.97\n",
      "conv_full/Conv_0.kernel[4,0,3]     -0.36      0.94     -0.44     -2.09      1.02  12721.44      0.86\n",
      "conv_full/Conv_0.kernel[4,0,4]     -0.05      0.98      0.08     -1.59      1.61   2195.50      0.96\n",
      "conv_full/Conv_0.kernel[4,0,5]     -0.17      0.94     -0.16     -1.74      1.20   3275.51      1.01\n",
      "conv_full/Conv_0.kernel[4,0,6]      0.03      0.91      0.05     -1.43      1.46   1534.10      1.07\n",
      "conv_full/Conv_0.kernel[4,0,7]      0.06      0.72      0.06     -1.08      1.31   1746.23      1.04\n",
      "                logits_full[0]     -0.79      7.25     -1.36    -13.05     11.38 159134.96      1.01\n",
      "                logits_full[1]     -0.27      7.23     -1.04    -11.69     13.01 160246.07      1.01\n",
      "                logits_full[2]     -0.12      7.46     -0.39    -12.69     12.34  89893.25      1.02\n",
      "                logits_full[3]      0.08      7.12     -0.26    -11.85     12.04 178783.61      1.01\n",
      "                logits_full[4]     -0.08      7.41     -0.62    -12.36     12.31 151645.36      1.01\n",
      "                logits_full[5]      0.60      6.64      0.36    -10.63     11.50  53050.38      1.02\n",
      "                logits_full[6]     -0.93      7.55     -1.36    -13.74     11.76 182508.11      1.01\n",
      "                logits_full[7]     -0.53      8.25     -1.21    -13.96     13.97 205525.04      1.01\n",
      "                logits_full[8]      1.04      6.04      0.81     -9.21     10.82  16286.20      1.02\n",
      "                logits_full[9]      0.58      7.10      0.17    -11.24     12.36 119626.06      1.01\n",
      "                    w1_full[0]     -0.00      1.00     -0.00     -1.63      1.67 310782.91      1.00\n",
      "                    w1_full[1]      0.00      1.00      0.00     -1.64      1.64 313455.19      1.00\n",
      "                    w1_full[2]      0.00      1.00      0.00     -1.61      1.68 314445.91      1.00\n",
      "                    w1_full[3]      0.00      1.00     -0.00     -1.63      1.66 312492.50      1.00\n",
      "                    w1_full[4]     -0.00      1.00      0.00     -1.61      1.69 309721.06      1.00\n",
      "                    w1_full[5]     -0.01      1.00     -0.01     -1.65      1.65 316488.67      1.00\n",
      "                    w1_full[6]     -0.00      1.00     -0.00     -1.66      1.62 311854.43      1.00\n",
      "                    w1_full[7]     -0.00      1.00     -0.00     -1.66      1.63 314356.17      1.00\n",
      "                    w1_full[8]     -0.00      1.00     -0.00     -1.63      1.65 312419.78      1.00\n",
      "                    w1_full[9]     -0.00      1.00      0.00     -1.61      1.66 312327.12      1.00\n",
      "                   w1_full[10]     -0.00      1.00     -0.01     -1.64      1.65 313992.73      1.00\n",
      "                   w1_full[11]      0.01      1.00      0.00     -1.64      1.64 304855.79      1.00\n",
      "                   w1_full[12]     -0.01      1.00     -0.00     -1.66      1.63 313953.51      1.00\n",
      "                   w1_full[13]      0.00      1.00      0.00     -1.65      1.65 315564.03      1.00\n",
      "                   w1_full[14]      0.00      1.00      0.00     -1.63      1.66 311271.66      1.00\n",
      "                   w1_full[15]     -0.01      1.00     -0.01     -1.67      1.62 310279.42      1.00\n",
      "                   w1_full[16]      0.00      1.00      0.00     -1.66      1.64 317160.44      1.00\n",
      "                   w1_full[17]     -0.01      1.00     -0.01     -1.64      1.64 315024.05      1.00\n",
      "                   w1_full[18]     -0.01      1.00     -0.01     -1.64      1.65 311904.92      1.00\n",
      "                   w1_full[19]     -0.00      1.00     -0.00     -1.62      1.68 315779.80      1.00\n",
      "                   w1_full[20]     -0.01      1.00     -0.01     -1.66      1.63 316012.77      1.00\n",
      "                   w1_full[21]     -0.00      1.00     -0.00     -1.65      1.63 316584.14      1.00\n",
      "                   w1_full[22]      0.01      1.00      0.01     -1.66      1.63 313583.30      1.00\n",
      "                   w1_full[23]     -0.00      1.00     -0.00     -1.63      1.65 314153.96      1.00\n",
      "                   w1_full[24]      0.00      1.00      0.00     -1.62      1.67 311435.76      1.00\n",
      "                   w1_full[25]     -0.01      1.00     -0.00     -1.64      1.66 314774.97      1.00\n",
      "                   w1_full[26]     -0.01      1.00     -0.01     -1.66      1.63 313504.00      1.00\n",
      "                   w1_full[27]      0.01      1.00      0.00     -1.62      1.66 313193.85      1.00\n",
      "                   w1_full[28]      0.00      1.00      0.01     -1.66      1.64 314149.52      1.00\n",
      "                   w1_full[29]      0.00      1.00      0.00     -1.66      1.63 314978.96      1.00\n",
      "                   w1_full[30]     -0.00      1.00     -0.00     -1.64      1.64 314198.77      1.00\n",
      "                   w1_full[31]     -0.00      1.00     -0.00     -1.64      1.63 312389.19      1.00\n",
      "                   w1_full[32]     -0.01      1.00     -0.01     -1.66      1.62 313326.70      1.00\n",
      "                   w1_full[33]     -0.01      1.00     -0.01     -1.65      1.63 315117.55      1.00\n",
      "                   w1_full[34]     -0.01      1.00     -0.01     -1.64      1.66 313650.90      1.00\n",
      "                   w1_full[35]      0.01      1.00      0.01     -1.64      1.64 314181.06      1.00\n",
      "                   w1_full[36]     -0.00      1.00     -0.00     -1.65      1.64 313732.18      1.00\n",
      "                   w1_full[37]      0.00      1.00      0.00     -1.65      1.64 314929.64      1.00\n",
      "                   w1_full[38]      0.00      1.00     -0.00     -1.64      1.66 314507.10      1.00\n",
      "                   w1_full[39]      0.01      1.00      0.01     -1.64      1.65 314924.65      1.00\n",
      "                   w1_full[40]     -0.01      1.00     -0.01     -1.62      1.66 315791.84      1.00\n",
      "                   w1_full[41]     -0.00      1.00     -0.00     -1.65      1.66 313653.59      1.00\n",
      "                   w1_full[42]      0.00      1.00      0.00     -1.64      1.65 310280.66      1.00\n",
      "                   w1_full[43]      0.00      1.00      0.01     -1.62      1.66 312093.18      1.00\n",
      "                   w1_full[44]      0.01      1.00      0.00     -1.65      1.65 316091.32      1.00\n",
      "                   w1_full[45]     -0.01      0.99     -0.01     -1.64      1.62 312282.04      1.00\n",
      "                   w1_full[46]      0.01      1.00      0.01     -1.62      1.66 311014.56      1.00\n",
      "                   w1_full[47]      0.00      1.00      0.01     -1.64      1.65 310883.09      1.00\n",
      "                   w1_full[48]      0.01      1.00      0.01     -1.65      1.64 314288.94      1.00\n",
      "                   w1_full[49]     -0.01      1.00     -0.01     -1.64      1.64 307990.11      1.00\n",
      "                   w1_full[50]     -0.00      1.00     -0.00     -1.63      1.67 312940.91      1.00\n",
      "                   w1_full[51]     -0.01      1.00     -0.01     -1.65      1.63 313867.84      1.00\n",
      "                   w1_full[52]      0.00      1.00      0.00     -1.66      1.63 319562.09      1.00\n",
      "                   w1_full[53]     -0.00      1.00     -0.00     -1.65      1.63 312072.57      1.00\n",
      "                   w1_full[54]     -0.01      1.00     -0.01     -1.67      1.62 318391.05      1.00\n",
      "                   w1_full[55]      0.01      1.00      0.00     -1.64      1.65 313547.54      1.00\n",
      "                   w1_full[56]      0.01      1.00      0.01     -1.63      1.68 310044.93      1.00\n",
      "                   w1_full[57]      0.00      0.99      0.00     -1.62      1.65 313371.69      1.00\n",
      "                   w1_full[58]     -0.01      1.00     -0.01     -1.66      1.63 313983.07      1.00\n",
      "                   w1_full[59]      0.00      1.00      0.00     -1.63      1.66 313213.12      1.00\n",
      "                   w1_full[60]     -0.01      1.00     -0.01     -1.67      1.63 314520.29      1.00\n",
      "                   w1_full[61]      0.01      1.00      0.00     -1.63      1.66 312145.99      1.00\n",
      "                   w1_full[62]     -0.00      1.00      0.00     -1.64      1.64 312405.64      1.00\n",
      "                   w1_full[63]      0.01      1.00      0.01     -1.65      1.63 312026.71      1.00\n",
      "                   w1_full[64]     -0.00      1.00     -0.01     -1.66      1.63 315512.23      1.00\n",
      "                   w1_full[65]      0.01      1.00      0.01     -1.66      1.64 309898.27      1.00\n",
      "                   w1_full[66]     -0.00      1.00      0.00     -1.66      1.62 313970.13      1.00\n",
      "                   w1_full[67]      0.00      1.00      0.00     -1.63      1.65 314985.54      1.00\n",
      "                   w1_full[68]      0.01      1.00      0.01     -1.65      1.64 311019.09      1.00\n",
      "                   w1_full[69]     -0.00      1.00     -0.00     -1.64      1.65 313958.33      1.00\n",
      "                   w1_full[70]     -0.01      1.00     -0.01     -1.66      1.63 314438.83      1.00\n",
      "                   w1_full[71]     -0.00      1.00     -0.00     -1.63      1.66 312947.30      1.00\n",
      "                   w1_full[72]      0.00      1.00      0.00     -1.64      1.64 311192.49      1.00\n",
      "                   w1_full[73]      0.00      1.00      0.00     -1.62      1.66 314261.01      1.00\n",
      "                   w1_full[74]      0.00      1.00      0.01     -1.63      1.66 314970.66      1.00\n",
      "                   w1_full[75]     -0.00      1.00     -0.00     -1.65      1.64 315332.86      1.00\n",
      "                   w1_full[76]      0.00      1.00      0.00     -1.62      1.66 315546.56      1.00\n",
      "                   w1_full[77]     -0.00      1.00     -0.00     -1.66      1.63 315835.16      1.00\n",
      "                   w1_full[78]     -0.00      1.00     -0.00     -1.65      1.63 312781.83      1.00\n",
      "                   w1_full[79]     -0.00      1.00     -0.00     -1.66      1.62 311031.71      1.00\n",
      "                   w1_full[80]     -0.01      1.00     -0.01     -1.65      1.63 312659.09      1.00\n",
      "                   w1_full[81]     -0.00      1.00     -0.01     -1.66      1.63 312643.31      1.00\n",
      "                   w1_full[82]      0.01      1.00      0.01     -1.62      1.66 313800.08      1.00\n",
      "                   w1_full[83]      0.00      1.00      0.00     -1.62      1.66 311052.64      1.00\n",
      "                   w1_full[84]     -0.00      1.00     -0.00     -1.66      1.63 312674.32      1.00\n",
      "                   w1_full[85]      0.01      1.00      0.01     -1.63      1.65 313169.98      1.00\n",
      "                   w1_full[86]     -0.01      1.00     -0.01     -1.64      1.66 317334.90      1.00\n",
      "                   w1_full[87]      0.00      1.00     -0.00     -1.64      1.65 316116.30      1.00\n",
      "                   w1_full[88]      0.00      1.00      0.00     -1.63      1.65 313234.93      1.00\n",
      "                   w1_full[89]     -0.01      1.00     -0.01     -1.67      1.63 313646.80      1.00\n",
      "                   w1_full[90]     -0.01      1.00     -0.01     -1.64      1.65 316738.67      1.00\n",
      "                   w1_full[91]     -0.01      1.00     -0.01     -1.64      1.66 310910.96      1.00\n",
      "                   w1_full[92]     -0.01      1.00     -0.01     -1.65      1.63 309668.53      1.00\n",
      "                   w1_full[93]      0.00      1.00      0.00     -1.66      1.62 307766.83      1.00\n",
      "                   w1_full[94]      0.00      1.00     -0.00     -1.65      1.64 308057.55      1.00\n",
      "                   w1_full[95]      0.01      1.00      0.01     -1.64      1.64 313447.20      1.00\n",
      "                   w1_full[96]      0.00      1.00      0.00     -1.65      1.64 315362.47      1.00\n",
      "                   w1_full[97]     -0.00      1.00     -0.00     -1.64      1.65 314372.89      1.00\n",
      "                   w1_full[98]      0.01      1.00      0.02     -1.66      1.65 312963.08      1.00\n",
      "                   w1_full[99]     -0.01      1.00     -0.01     -1.65      1.63 312484.38      1.00\n",
      "                  w1_full[100]     -0.00      1.00     -0.01     -1.65      1.64 308986.97      1.00\n",
      "                  w1_full[101]      0.00      1.00      0.00     -1.65      1.64 316288.09      1.00\n",
      "                  w1_full[102]      0.01      1.00      0.01     -1.62      1.67 313686.95      1.00\n",
      "                  w1_full[103]     -0.00      1.00     -0.00     -1.68      1.62 309460.25      1.00\n",
      "                  w1_full[104]      0.01      1.00      0.01     -1.66      1.63 314374.58      1.00\n",
      "                  w1_full[105]      0.01      1.00      0.01     -1.64      1.64 314708.20      1.00\n",
      "                  w1_full[106]      0.01      1.00      0.01     -1.62      1.68 316535.28      1.00\n",
      "                  w1_full[107]      0.00      1.00     -0.00     -1.62      1.66 312150.30      1.00\n",
      "                  w1_full[108]      0.01      1.00      0.01     -1.63      1.67 311082.76      1.00\n",
      "                  w1_full[109]      0.01      1.00      0.01     -1.66      1.63 310765.97      1.00\n",
      "                  w1_full[110]     -0.01      1.00     -0.02     -1.64      1.65 314173.76      1.00\n",
      "                  w1_full[111]      0.01      1.01      0.01     -1.65      1.67 310325.64      1.00\n",
      "                  w1_full[112]     -0.01      1.00     -0.01     -1.64      1.65 315209.23      1.00\n",
      "                  w1_full[113]     -0.00      1.00     -0.00     -1.67      1.62 315620.23      1.00\n",
      "                  w1_full[114]      0.01      1.00      0.00     -1.63      1.67 313884.68      1.00\n",
      "                  w1_full[115]      0.00      1.00      0.00     -1.66      1.63 312198.79      1.00\n",
      "                  w1_full[116]     -0.00      1.00     -0.00     -1.68      1.61 310979.17      1.00\n",
      "                  w1_full[117]     -0.00      1.00      0.00     -1.64      1.64 316808.25      1.00\n",
      "                  w1_full[118]      0.01      1.00      0.01     -1.65      1.64 308877.28      1.00\n",
      "                  w1_full[119]     -0.01      1.00     -0.01     -1.63      1.66 315404.49      1.00\n",
      "                  w1_full[120]     -0.01      1.00     -0.01     -1.64      1.64 313406.09      1.00\n",
      "                  w1_full[121]      0.01      1.00      0.01     -1.62      1.67 315581.90      1.00\n",
      "                  w1_full[122]      0.00      1.00      0.00     -1.64      1.65 310644.69      1.00\n",
      "                  w1_full[123]      0.01      1.00      0.01     -1.64      1.65 311113.49      1.00\n",
      "                  w1_full[124]      0.01      1.00      0.01     -1.63      1.65 312263.24      1.00\n",
      "                  w1_full[125]      0.00      1.00      0.00     -1.67      1.62 311543.60      1.00\n",
      "                  w1_full[126]      0.00      1.00      0.01     -1.64      1.65 313381.90      1.00\n",
      "                  w1_full[127]      0.00      1.00      0.00     -1.64      1.64 313679.08      1.00\n",
      "                    w2_full[0]     -0.00      1.00     -0.01     -1.57      1.69  25627.86      1.00\n",
      "                    w2_full[1]      0.00      0.99     -0.01     -1.59      1.68  26243.68      1.00\n",
      "                    w2_full[2]      0.01      1.00      0.01     -1.67      1.62  26779.44      1.00\n",
      "                    w2_full[3]     -0.00      0.99     -0.00     -1.60      1.67  25375.62      1.00\n",
      "                    w2_full[4]      0.01      0.99      0.01     -1.66      1.60  25406.02      1.00\n",
      "                    w2_full[5]      0.01      0.99      0.01     -1.71      1.57  26482.15      1.00\n",
      "                    w2_full[6]      0.02      1.00      0.03     -1.67      1.61  25407.21      1.00\n",
      "                    w2_full[7]     -0.03      1.00     -0.02     -1.67      1.61  26284.44      1.00\n",
      "                    w2_full[8]     -0.01      0.99     -0.02     -1.64      1.64  26544.56      1.00\n",
      "                    w2_full[9]     -0.02      1.01     -0.02     -1.70      1.62  26235.52      1.00\n",
      "                   w2_full[10]      0.02      1.00      0.02     -1.69      1.61  25812.25      1.00\n",
      "                   w2_full[11]     -0.01      1.01     -0.02     -1.74      1.61  25505.04      1.00\n",
      "                   w2_full[12]      0.01      1.01      0.00     -1.64      1.67  26757.91      1.00\n",
      "                   w2_full[13]      0.01      1.00      0.02     -1.66      1.62  25402.16      1.00\n",
      "                   w2_full[14]      0.01      0.98      0.00     -1.63      1.61  26243.65      1.00\n",
      "                   w2_full[15]     -0.00      1.00     -0.01     -1.67      1.61  25941.18      1.00\n",
      "                   w2_full[16]      0.03      0.99      0.03     -1.57      1.68  25970.70      1.00\n",
      "                   w2_full[17]      0.03      0.99      0.03     -1.58      1.65  25788.87      1.00\n",
      "                   w2_full[18]     -0.01      0.99     -0.01     -1.65      1.60  25927.26      1.00\n",
      "                   w2_full[19]     -0.01      1.00     -0.01     -1.70      1.59  27320.94      1.00\n",
      "                   w2_full[20]     -0.02      1.00     -0.03     -1.60      1.66  26391.80      1.00\n",
      "                   w2_full[21]      0.01      1.02      0.01     -1.67      1.65  26783.21      1.00\n",
      "                   w2_full[22]      0.00      1.00     -0.01     -1.66      1.62  26250.35      1.00\n",
      "                   w2_full[23]      0.01      1.00      0.01     -1.67      1.63  26026.86      1.00\n",
      "                   w2_full[24]      0.00      1.00     -0.01     -1.61      1.69  25860.84      1.00\n",
      "                   w2_full[25]      0.03      0.99      0.03     -1.63      1.63  25711.37      1.00\n",
      "                   w2_full[26]     -0.00      1.00     -0.00     -1.62      1.65  26548.84      1.00\n",
      "                   w2_full[27]     -0.00      0.99     -0.00     -1.57      1.67  25505.00      1.00\n",
      "                   w2_full[28]      0.01      0.99     -0.00     -1.58      1.68  26534.68      1.00\n",
      "                   w2_full[29]      0.01      1.00      0.01     -1.66      1.62  25631.24      1.00\n",
      "                   w2_full[30]     -0.01      1.00     -0.01     -1.61      1.68  25085.83      1.00\n",
      "                   w2_full[31]      0.03      1.00      0.03     -1.69      1.61  25306.82      1.00\n",
      "                    w3_full[0]     -0.02      1.06     -0.01     -1.77      1.66   6256.81      1.00\n",
      "                    w3_full[1]     -0.02      1.03     -0.01     -1.69      1.69   6803.36      1.00\n",
      "                    w3_full[2]     -0.13      1.13     -0.17     -2.02      1.66   7251.49      1.00\n",
      "                    w3_full[3]     -0.01      1.09     -0.01     -1.83      1.75   6578.48      1.01\n",
      "                    w3_full[4]      0.02      1.09      0.01     -1.72      1.79   6275.80      0.99\n",
      "                    w3_full[5]      0.04      1.06      0.03     -1.74      1.73   6719.00      1.01\n",
      "                    w3_full[6]     -0.07      1.05     -0.06     -1.77      1.68   6580.95      0.99\n",
      "                    w3_full[7]      0.05      1.12      0.03     -1.89      1.82   6830.26      1.00\n",
      "                    w3_full[8]     -0.01      1.01      0.00     -1.67      1.62   6737.16      0.99\n",
      "                    w3_full[9]      0.07      1.04      0.09     -1.53      1.84   6734.17      1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summary of full weight matrix model\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy on test set\n",
    "logits = posterior_predictive_test_1['logits_full']\n",
    "\n",
    "print(\"Success posterior test = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "# Accuracy on training set\n",
    "logits = posterior_predictive_train_1['logits_full']\n",
    "print(\"Success posterior training = %.3f\" % accuracy(logits, y))\n",
    "\n",
    "logits = prior_predictive_1['logits_full']\n",
    "print(\"Success prior = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "print(\"Posterior test diagnostics:\")\n",
    "numpyro.diagnostics.print_summary(posterior_samples_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "jax:Python",
   "language": "python",
   "name": "conda-env-jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
