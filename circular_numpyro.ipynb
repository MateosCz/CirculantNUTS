{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ki5fKrZBuNL",
    "outputId": "69eae75e-bc10-4509-8eea-d677361f355d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpyro in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: jax>=0.4 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.4.10)\n",
      "Requirement already satisfied: jaxlib>=0.4 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.4.10+cuda11.cudnn86)\n",
      "Requirement already satisfied: multipledispatch in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.6.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (4.65.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (0.1.0)\n",
      "Requirement already satisfied: opt-einsum in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (1.10.1)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from multipledispatch->numpyro) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jax.numpy.fft import irfft, rfft, fft, ifft\n",
    "\n",
    "from jax import grad, jit, vmap\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import jax\n",
    "\n",
    "!pip install numpyro\n",
    "import numpyro\n",
    "from numpyro import handlers\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "import numpyro.contrib.module as module\n",
    "\n",
    "!pip install -q flax\n",
    "from flax import linen as nn\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "\n",
    "matplotlib.use(\"Agg\")  # noqa: E402\n",
    "np.random.seed(0)\n",
    "key = numpyro.prng_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices(backend='gpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Hu9LZWJPCGh1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numpy_collate(batch):\n",
    "  if isinstance(batch[0], np.ndarray):\n",
    "    return np.stack(batch)\n",
    "  elif isinstance(batch[0], (tuple,list)):\n",
    "    transposed = zip(*batch)\n",
    "    return [numpy_collate(samples) for samples in transposed]\n",
    "  else:\n",
    "    return np.array(batch)\n",
    "\n",
    "\n",
    "class NumpyLoader(torch.utils.data.DataLoader):\n",
    "  def __init__(self, dataset, batch_size=1,\n",
    "                shuffle=False, sampler=None,\n",
    "                batch_sampler=None, num_workers=0,\n",
    "                pin_memory=False, drop_last=False,\n",
    "                timeout=0, worker_init_fn=None):\n",
    "    super(self.__class__, self).__init__(dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn)\n",
    "\n",
    "class FlattenAndCast(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.ravel(np.array(pic, dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KKqyhf6UCIFw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mnist(n, m):\n",
    "    \"\"\"\n",
    "    Download MNIST and return train and evaluation sets.\n",
    "    \"\"\"\n",
    "    mnist = datasets.MNIST('data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=FlattenAndCast())\n",
    "    mnist = list(mnist)\n",
    "    # One batch with all of mnist\n",
    "    train_loader = NumpyLoader(mnist, batch_size=len(mnist), num_workers=0)\n",
    "    x, y = list(train_loader)[0]\n",
    "    # Normalize\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    # Train and test set\n",
    "    train_x, train_y = x[0:n], y[0:n]\n",
    "    val_x, val_y = x[n:n+m], y[n:n+m]\n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CvNmAUrFCKOi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class flax_CNN(nn.Module):\n",
    "    @nn.compact   \n",
    "    def __call__(self, x):\n",
    "        #print(x.shape)\n",
    "        x_length = x.shape[0]\n",
    "        x = nn.Conv(features = 8, kernel_size = (5,5),strides = (1,1), \n",
    "                   padding = (2,2), \n",
    "                   use_bias= False)(x)\n",
    "        #print(x.shape[0])\n",
    "        x = nn.max_pool(x,window_shape=(2,2),strides = (2,2))\n",
    "        all_len = len(x.flatten())\n",
    "        x = x.reshape((x_length, int((all_len/x_length)) ))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfmvSjGQCMNE",
    "outputId": "42e353bb-e1e2-43cb-e749-caf48374b4cf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n",
      "(1000,)\n",
      "(784000,)\n"
     ]
    }
   ],
   "source": [
    "_x, _y, _xv, _yv = get_mnist(50000,10000)\n",
    "\n",
    "# Training\n",
    "N=1000 \n",
    "# Test\n",
    "M=300\n",
    "\n",
    "# Get the training and test data from the MNIST global variables\n",
    "x, y, xv, yv = _x[0:N], _y[0:N], _xv[N:N+M], _yv[N:N+M]\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(jnp.ravel(x.reshape((-1,1,28,28))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ip2VF9VjCNUp",
    "outputId": "8d33bd52-dc07-4201-827b-5285c1ca5f59",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                flax_CNN Summary                                \u001b[0m\n",
      "┏━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams          \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│        │ flax_CNN │ \u001b[2mfloat32\u001b[0m[1000,28,… │ \u001b[2mfloat32\u001b[0m[1000,156… │                  │\n",
      "├────────┼──────────┼───────────────────┼───────────────────┼──────────────────┤\n",
      "│ Conv_0 │ Conv     │ \u001b[2mfloat32\u001b[0m[1000,28,… │ \u001b[2mfloat32\u001b[0m[1000,28,… │ kernel:          │\n",
      "│        │          │                   │                   │ \u001b[2mfloat32\u001b[0m[5,5,1,8] │\n",
      "│        │          │                   │                   │                  │\n",
      "│        │          │                   │                   │ \u001b[1m200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m      │\n",
      "├────────┼──────────┼───────────────────┼───────────────────┼──────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\n",
      "└────────┴──────────┴───────────────────┴───────────────────┴──────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m\u001b[1m                          \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim1 = 800\n",
    "dim2 = 128\n",
    "# dim3 = 128\n",
    "# dim4 = 32\n",
    "key = random.PRNGKey(0)\n",
    "d1 = dist.Bernoulli(jnp.array(0.5)).expand([2*28*28]).sample(key)\n",
    "d2 = dist.Bernoulli(jnp.array(0.5)).expand([dim1]).sample(key)\n",
    "d1 = 2*d1 - 1\n",
    "d2 = 2*d2 - 1\n",
    "conv = flax_CNN() #from (200,28,28) to (200, 1568)\n",
    "\n",
    "rng_key = random.PRNGKey(1)\n",
    "\n",
    "print(conv.tabulate(jax.random.PRNGKey(0), x.reshape((-1,28,28,1))))\n",
    "\n",
    "# with numpyro.handlers.seed(rng_seed=0):\n",
    "#     numpyro_conv = module.random_flax_module(\"conv\", conv, dist.Normal(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B9ZwnElxCP2Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def circ_matmul(x, w):\n",
    "    # xw = fft(fft(w)*ifft(x)).real\n",
    "    # Note the use of the n argument to get right output shape\n",
    "    xw = irfft(jnp.conj(rfft(w)) * rfft(x), n=w.shape[0])\n",
    "    return xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qmk0rGrVCQ90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the non-linearity we use in our neural network\n",
    "def nonlin(x):\n",
    "    return jnp.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "x1N4sDqtCSvJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(x, y=None, dim1 = dim1, dim2 = dim2):\n",
    "    w1 = numpyro.sample(\"w1\", dist.Normal(0,1).expand([2*28*28]).to_event(1))\n",
    "    b1 = numpyro.sample(\"b1\", dist.Normal(0,1).expand([dim1]).to_event(1))\n",
    "\n",
    "    w2 = numpyro.sample(\"w2\", dist.Normal(0,1).expand([dim1]).to_event(1))\n",
    "    b2 = numpyro.sample(\"b2\", dist.Normal(0,1).expand([dim2]).to_event(1))\n",
    "\n",
    "#     w3 = numpyro.sample(\"w3\", dist.Normal(0,1).expand([dim2]).to_event(1))\n",
    "#     b3 = numpyro.sample(\"b3\", dist.Normal(0,1).expand([dim3]).to_event(1))\n",
    "\n",
    "#     w4 = numpyro.sample(\"w4\", dist.Normal(0,1).expand([dim3]).to_event(1))\n",
    "#     b4 = numpyro.sample(\"b4\", dist.Normal(0,1).expand([dim4]).to_event(1))        \n",
    "\n",
    "    # w5 = numpyro.sample(\"w5\", dist.Normal(0,1).expand([dim4,10]).to_event(2))\n",
    "    # b5 = numpyro.sample(\"b5\", dist.Normal(0,1).expand([10]).to_event(1))\n",
    "    \n",
    "    \n",
    "    w5 = numpyro.sample(\"w5\", dist.Normal(0,1).expand([dim2,10]).to_event(2))\n",
    "    b5 = numpyro.sample(\"b5\", dist.Normal(0,1).expand([10]).to_event(1))    \n",
    "\n",
    "    # Convolution\n",
    "    #variables = conv.init(random.PRNGKey(3),x.reshape((-1,1,28,28)))\n",
    "    #conv_model = conv.apply(variables,x.reshape((-1,1,28,28)))\n",
    "    #conv = flax_CNN()\n",
    "    conv_numpyro = module.random_flax_module(\"conv\", conv, dist.Normal(0, 1), input_shape=((x.shape[0],28,28,1)))\n",
    "    cx = nonlin(conv_numpyro(x.reshape((-1,28,28,1))))\n",
    "    #print(conv_numpyro(x.reshape((-1,28,28,1))))\n",
    "\n",
    "    # Layer 1: dim1\n",
    "    h1 = circ_matmul(cx, w1)\n",
    "    h1 = nonlin(h1[:, 0:dim1] + b1)\n",
    "    # Layer 2: dim2\n",
    "    h2 = circ_matmul(h1, w2)\n",
    "    h2 = nonlin(h2[:, 0:dim2] + b2)\n",
    "\n",
    "\n",
    "#     h3 = circ_matmul(h2, w3)\n",
    "#     h3 = nonlin(h3[:, 0:dim3] + b3)\n",
    "\n",
    "#     h4 = circ_matmul(h3, w4)\n",
    "#     h4 = nonlin(h4[:, 0:dim4] + b4)\n",
    "    \n",
    "\n",
    "  \n",
    "    # Layer 3: dim=10 (logits)\n",
    "    h5 = jnp.matmul(h2,w5) + b5\n",
    "    # Register the logits for easy prediction\n",
    "    numpyro.deterministic(\"logits\", h5)\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"labels\", x.shape[0]):\n",
    "        y_obs = numpyro.sample(\"y_obs\", dist.CategoricalLogits(logits = h5), obs = y, rng_key=key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0b5cQ8cVKasn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_2(x, y=None):\n",
    "  w1_f = numpyro.sample(\"w1_f\", dist.Normal(0,1).expand([2*28*28,dim1]).to_event(1)) #weight matrix dimension: (indim(1568), h1dim(dim1 128))\n",
    "  b1_f = numpyro.sample(\"b1_f\", dist.Normal(0,1).expand([dim1]).to_event(1)) # bias dimension: (128,)\n",
    "\n",
    "  w2_f = numpyro.sample(\"w2_f\", dist.Normal(0,1).expand([dim1,dim2]).to_event(1)) #weight matrix dimension: (h1dim(dim1), h2dim(dim2))\n",
    "  b2_f = numpyro.sample(\"b2_f\", dist.Normal(0,1).expand([dim2]).to_event(1)) # bias dimension: (dim2,)\n",
    "\n",
    "#   w3 = numpyro.sample(\"w3\", dist.Normal(0,1).expand([dim2,dim3]).to_event(2)) #weight matrix dimension: (h2dim(dim2), outdim(10))\n",
    "#   b3 = numpyro.sample(\"b3\", dist.Normal(0,1).expand([dim3]).to_event(1)) # bias dimension: (outdim(10))\n",
    "\n",
    "#   w4 = numpyro.sample(\"w4\", dist.Normal(0,1).expand([dim3,dim4]).to_event(2)) #weight matrix dimension: (h2dim(dim2), outdim(10))\n",
    "#   b4 = numpyro.sample(\"b4\", dist.Normal(0,1).expand([dim4]).to_event(1)) # bias dimension: (outdim(10))\n",
    "\n",
    "  w5_f = numpyro.sample(\"w5_f\", dist.Normal(0,1).expand([dim2,10]).to_event(2)) #weight matrix dimension: (h2dim(dim2), outdim(10))\n",
    "  b5_f = numpyro.sample(\"b5_f\", dist.Normal(0,1).expand([10]).to_event(1)) # bias dimension: (outdim(10))  \n",
    "\n",
    "  conv_numpyro = module.random_flax_module(\"conv_f\", conv, dist.Normal(0, 1), input_shape=((x.shape[0],28,28,1)))\n",
    "  cx = nonlin(conv_numpyro(x.reshape((-1,28,28,1))))\n",
    "\n",
    "\n",
    "  h1 = nonlin(jnp.matmul(cx,w1_f) + b1_f)\n",
    "\n",
    "  h2 = nonlin(jnp.matmul(h1,w2_f) + b2_f)\n",
    "\n",
    "\n",
    "#   h3 = nonlin(jnp.matmul(h2,w3_f) + b3_f)\n",
    "\n",
    "#   h4 = nonlin(jnp.matmul(h3,w4_f) + b4_f)  \n",
    "\n",
    "  h5 = jnp.matmul(h2,w5_f) + b5_f\n",
    "\n",
    "  # Register the logits for easy prediction\n",
    "  numpyro.deterministic(\"logits_f\", h5)\n",
    "\n",
    "\n",
    "  # Likelihood\n",
    "  with numpyro.plate(\"labels_f\", x.shape[0]):\n",
    "      y_obs_f = numpyro.sample(\"y_obs_f\", dist.CategoricalLogits(logits = h5), obs = y, rng_key=key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxaB3q9g-e0N",
    "outputId": "c44fe55c-d96d-42b9-fbb6-24b3ec331a2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109/886459667.py:7: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  mcmc = MCMC(kernel,\n",
      "sample: 100%|██████████| 150/150 [14:47<00:00,  5.92s/it, 1023 steps of size 2.05e-03. acc. prob=0.86]\n",
      "sample: 100%|██████████| 150/150 [14:51<00:00,  5.94s/it, 1023 steps of size 2.00e-03. acc. prob=0.87]\n"
     ]
    }
   ],
   "source": [
    "# Default max_tree_depth is 10\n",
    "kernel = NUTS(model_2,\n",
    "              target_accept_prob = 0.8,\n",
    "              max_tree_depth = 10\n",
    "              )\n",
    "\n",
    "mcmc = MCMC(kernel,\n",
    "            num_samples = 100,\n",
    "            num_warmup = 50,\n",
    "            num_chains = 2,\n",
    "            progress_bar = True)\n",
    "\n",
    "mcmc.run(random.PRNGKey(0), x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20s9MSMHl8GF",
    "outputId": "209762fd-9d02-43b4-cf8e-8b42ceffb89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function devices at 0x7f85b9f517e0>\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKsFyO0kCUNg",
    "outputId": "5d3ba65a-016d-4747-af7c-b123fc123736"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109/2488225058.py:7: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  mcmc_1 = MCMC(kernel_1,\n",
      "sample: 100%|██████████| 150/150 [10:49<00:00,  4.33s/it, 1023 steps of size 2.24e-03. acc. prob=0.95]\n",
      "sample: 100%|██████████| 150/150 [10:44<00:00,  4.30s/it, 1023 steps of size 2.76e-03. acc. prob=0.76]\n"
     ]
    }
   ],
   "source": [
    "# Default max_tree_depth is 10\n",
    "kernel_1 = NUTS(model,\n",
    "              target_accept_prob = 0.8,\n",
    "              max_tree_depth = 10\n",
    "              )\n",
    "\n",
    "mcmc_1 = MCMC(kernel_1,\n",
    "            num_samples = 100,\n",
    "            num_warmup = 50,\n",
    "            num_chains = 2,\n",
    "            progress_bar = True)\n",
    "\n",
    "mcmc_1.run(random.PRNGKey(0), x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "5LlrMZnPRiVt",
    "outputId": "5400cb48-112d-4147-aa98-f639b3b4dd6a"
   },
   "outputs": [],
   "source": [
    "posterior_samples = mcmc.get_samples()\n",
    "\n",
    "\n",
    "posterior_predictive_test = numpyro.infer.Predictive(model_2, posterior_samples)(\n",
    "        jax.random.PRNGKey(3),xv)\n",
    "\n",
    "posterior_predictive_train = numpyro.infer.Predictive(model_2, posterior_samples)(\n",
    "        jax.random.PRNGKey(3),x)\n",
    "\n",
    "prior_predictive = numpyro.infer.Predictive(model_2, num_samples=500)(\n",
    "        jax.random.PRNGKey(3),xv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aW437_KjCcBA"
   },
   "outputs": [],
   "source": [
    "posterior_samples_1 = mcmc_1.get_samples()\n",
    "\n",
    "\n",
    "posterior_predictive_test_1 = numpyro.infer.Predictive(model, posterior_samples_1)(\n",
    "        jax.random.PRNGKey(3),xv)\n",
    "\n",
    "posterior_predictive_train_1 = numpyro.infer.Predictive(model, posterior_samples_1)(\n",
    "        jax.random.PRNGKey(3),x)\n",
    "\n",
    "prior_predictive_1 = numpyro.infer.Predictive(model, num_samples=500)(\n",
    "        jax.random.PRNGKey(3),xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6G-VFAvFZoFA",
    "outputId": "4198e197-74bc-437a-809a-2608d079961e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arviz in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (0.15.1)\n",
      "Requirement already satisfied: setuptools>=60.0.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (67.7.2)\n",
      "Requirement already satisfied: matplotlib>=3.2 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (1.10.1)\n",
      "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (23.1)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (2.0.1)\n",
      "Requirement already satisfied: xarray>=0.21.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (2023.5.0)\n",
      "Requirement already satisfied: h5netcdf>=1.0.2 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (4.5.0)\n",
      "Requirement already satisfied: xarray-einstats>=0.3 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from arviz) (0.5.1)\n",
      "Requirement already satisfied: h5py in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from h5netcdf>=1.0.2->arviz) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from matplotlib>=3.2->arviz) (5.12.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from pandas>=1.3.0->arviz) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from pandas>=1.3.0->arviz) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.2->arviz) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.2->arviz) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install arviz\n",
    "import arviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fF-Y7a1HhiPy"
   },
   "outputs": [],
   "source": [
    "def accuracy(pred, data):\n",
    "  \"\"\"\n",
    "  Calculate accuracy of predicted labels (integers).\n",
    "\n",
    "  pred: predictions, ndarray[sample_index, chain_index, data_index, logits]\n",
    "  data: actual data (digit), ndarray[data_index]\n",
    "\n",
    "  Prediction is taken as most common predicted value.\n",
    "  Returns accuracy (#correct/#total).\n",
    "  \"\"\"\n",
    "  n=data.shape[0]\n",
    "  correct=0\n",
    "  total=0\n",
    "  for i in range(0, n):\n",
    "      # Get most common prediction value from logits\n",
    "      pred_i=int(jnp.argmax(jnp.sum(pred[:,i,:],0)))\n",
    "      # Compare prediction with data\n",
    "      if int(data[i])==int(pred_i):\n",
    "          correct+=1.0\n",
    "      total+=1.0\n",
    "  # Return fractional accuracy\n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQl0pyAEfXi6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuir-trcRt5m",
    "outputId": "ead3abba-ae8b-41e0-d077-4c6500a5bba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success posterior test = 0.883\n",
      "Success posterior training = 1.000\n",
      "Success prior = 0.153\n",
      "Posterior test diagnostics:\n",
      "\n",
      "                 mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "logits_f[0]     -1.58     14.07     -2.78    -25.45     21.06  32888.18      1.02\n",
      "logits_f[1]     -2.41     14.37     -3.82    -25.99     22.14  35610.87      1.02\n",
      "logits_f[2]      0.79     12.20      0.41    -19.77     20.37  35679.58      1.02\n",
      "logits_f[3]     -0.70     12.15     -1.12    -21.07     18.76  55123.87      1.02\n",
      "logits_f[4]     -0.09     12.85     -0.63    -21.44     21.13  53809.85      1.02\n",
      "logits_f[5]      0.45     11.49      0.11    -18.09     19.76  15910.72      1.02\n",
      "logits_f[6]     -1.48     13.71     -2.69    -25.15     20.04  57032.00      1.01\n",
      "logits_f[7]     -0.30     14.89     -1.68    -24.96     24.53  46335.20      1.01\n",
      "logits_f[8]      2.30     11.57      1.89    -16.87     21.25  55068.99      1.02\n",
      "logits_f[9]      1.70     13.08      1.02    -20.42     22.78  35857.70      1.02\n",
      "    y_obs_f      4.64      2.98      5.00      0.00      9.00  60620.73      1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Diagnostics from Arviz\n",
    "#mcmc.print_summary()\n",
    "#data = arviz.from_numpyro(mcmc, prior=prior_predictive, posterior_predictive=posterior_predictive_test)\n",
    "#summary = arviz.summary(data)\n",
    "#print(summary)\n",
    "\n",
    "#arviz.plot_trace(posterior_samples)\n",
    "\n",
    "# Diagnostics from Pyro\n",
    "#report = mcmc.summary()\n",
    "\n",
    "# Accuracy on test set\n",
    "logits = posterior_predictive_test['logits_f']\n",
    "print(\"Success posterior test = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "# Accuracy on training set\n",
    "logits = posterior_predictive_train['logits_f']\n",
    "print(\"Success posterior training = %.3f\" % accuracy(logits, y))\n",
    "\n",
    "logits = prior_predictive['logits_f']\n",
    "print(\"Success prior = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "print(\"Posterior test diagnostics:\")\n",
    "numpyro.diagnostics.print_summary(posterior_predictive_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP284gjyDB-E",
    "outputId": "79284346-f872-4cb6-f56c-e8c509f01ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success posterior test = 0.907\n",
      "Success posterior training = 1.000\n",
      "Success prior = 0.137\n",
      "Posterior test diagnostics:\n",
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      " logits[0]     -1.24     14.47     -2.54    -24.94     23.42  48835.61      1.01\n",
      " logits[1]     -1.09     13.87     -2.30    -24.18     22.60  51045.04      1.01\n",
      " logits[2]     -0.75     14.53     -1.18    -24.81     23.15  40331.78      1.01\n",
      " logits[3]      0.54     12.72      0.07    -20.02     22.08  53181.66      1.01\n",
      " logits[4]     -1.25     14.62     -1.79    -24.92     23.47  53077.15      1.02\n",
      " logits[5]      1.49     11.55      0.93    -17.03     20.62  55902.17      1.01\n",
      " logits[6]     -2.27     15.51     -2.96    -28.84     23.40  57791.70      1.01\n",
      " logits[7]     -1.20     16.22     -2.54    -27.04     26.90  48126.08      1.01\n",
      " logits[8]      3.42     12.11      2.86    -16.38     23.59  54406.70      1.01\n",
      " logits[9]      3.62     12.36      3.14    -16.94     23.82  30721.54      1.02\n",
      "     y_obs      4.64      2.97      5.00      0.00      9.00  61555.57      1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on test set\n",
    "logits = posterior_predictive_test_1['logits']\n",
    "\n",
    "print(\"Success posterior test = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "# Accuracy on training set\n",
    "logits = posterior_predictive_train_1['logits']\n",
    "print(\"Success posterior training = %.3f\" % accuracy(logits, y))\n",
    "\n",
    "logits = prior_predictive_1['logits']\n",
    "print(\"Success prior = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "print(\"Posterior test diagnostics:\")\n",
    "numpyro.diagnostics.print_summary(posterior_predictive_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "jax:Python",
   "language": "python",
   "name": "conda-env-jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
