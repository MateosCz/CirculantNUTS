{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ki5fKrZBuNL",
    "outputId": "69eae75e-bc10-4509-8eea-d677361f355d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpyro in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: jax>=0.4 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.4.10)\n",
      "Requirement already satisfied: jaxlib>=0.4 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.4.10+cuda11.cudnn86)\n",
      "Requirement already satisfied: multipledispatch in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (0.6.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (1.24.3)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from numpyro) (4.65.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (0.1.0)\n",
      "Requirement already satisfied: opt-einsum in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from jax>=0.4->numpyro) (1.10.1)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages (from multipledispatch->numpyro) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/jax/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jax.numpy.fft import irfft, rfft, fft, ifft\n",
    "\n",
    "from jax import grad, jit, vmap\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "import jax\n",
    "\n",
    "!pip install numpyro\n",
    "import numpyro\n",
    "from numpyro import handlers\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "import numpyro.contrib.module as module\n",
    "\n",
    "!pip install -q flax\n",
    "from flax import linen as nn\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "\n",
    "matplotlib.use(\"Agg\")  # noqa: E402\n",
    "np.random.seed(0)\n",
    "key = numpyro.prng_key()\n",
    "numpyro.set_host_device_count(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices(backend='gpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Hu9LZWJPCGh1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numpy_collate(batch):\n",
    "  if isinstance(batch[0], np.ndarray):\n",
    "    return np.stack(batch)\n",
    "  elif isinstance(batch[0], (tuple,list)):\n",
    "    transposed = zip(*batch)\n",
    "    return [numpy_collate(samples) for samples in transposed]\n",
    "  else:\n",
    "    return np.array(batch)\n",
    "\n",
    "\n",
    "class NumpyLoader(torch.utils.data.DataLoader):\n",
    "  def __init__(self, dataset, batch_size=1,\n",
    "                shuffle=False, sampler=None,\n",
    "                batch_sampler=None, num_workers=0,\n",
    "                pin_memory=False, drop_last=False,\n",
    "                timeout=0, worker_init_fn=None):\n",
    "    super(self.__class__, self).__init__(dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn)\n",
    "\n",
    "class FlattenAndCast(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.ravel(np.array(pic, dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KKqyhf6UCIFw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mnist(n, m):\n",
    "    \"\"\"\n",
    "    Download MNIST and return train and evaluation sets.\n",
    "    \"\"\"\n",
    "    mnist = datasets.MNIST('data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=FlattenAndCast())\n",
    "    mnist = list(mnist)\n",
    "    # One batch with all of mnist\n",
    "    train_loader = NumpyLoader(mnist, batch_size=len(mnist), num_workers=0)\n",
    "    x, y = list(train_loader)[0]\n",
    "    # Normalize\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    # Train and test set\n",
    "    train_x, train_y = x[0:n], y[0:n]\n",
    "    val_x, val_y = x[n:n+m], y[n:n+m]\n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CvNmAUrFCKOi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class flax_CNN(nn.Module):\n",
    "    @nn.compact   \n",
    "    def __call__(self, x):\n",
    "        #print(x.shape)\n",
    "        x_length = x.shape[0]\n",
    "        x = nn.Conv(features = 8, kernel_size = (5,5),strides = (1,1), \n",
    "                   padding = (2,2), \n",
    "                   use_bias= False)(x)\n",
    "        #print(x.shape[0])\n",
    "        x = nn.max_pool(x,window_shape=(2,2),strides = (2,2))\n",
    "        all_len = len(x.flatten())\n",
    "        x = x.reshape((x_length, int((all_len/x_length)) ))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfmvSjGQCMNE",
    "outputId": "42e353bb-e1e2-43cb-e749-caf48374b4cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "_x, _y, _xv, _yv = get_mnist(50000,10000)\n",
    "\n",
    "# Training\n",
    "N=1000 \n",
    "# Test\n",
    "M=300\n",
    "\n",
    "# Get the training and test data from the MNIST global variables\n",
    "x, y, xv, yv = _x[0:N], _y[0:N], _xv[N:N+M], _yv[N:N+M]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ip2VF9VjCNUp",
    "outputId": "8d33bd52-dc07-4201-827b-5285c1ca5f59",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                flax_CNN Summary                                \u001b[0m\n",
      "┏━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams          \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
      "│        │ flax_CNN │ \u001b[2mfloat32\u001b[0m[1000,28,… │ \u001b[2mfloat32\u001b[0m[1000,156… │                  │\n",
      "├────────┼──────────┼───────────────────┼───────────────────┼──────────────────┤\n",
      "│ Conv_0 │ Conv     │ \u001b[2mfloat32\u001b[0m[1000,28,… │ \u001b[2mfloat32\u001b[0m[1000,28,… │ kernel:          │\n",
      "│        │          │                   │                   │ \u001b[2mfloat32\u001b[0m[5,5,1,8] │\n",
      "│        │          │                   │                   │                  │\n",
      "│        │          │                   │                   │ \u001b[1m200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m      │\n",
      "├────────┼──────────┼───────────────────┼───────────────────┼──────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m│\n",
      "└────────┴──────────┴───────────────────┴───────────────────┴──────────────────┘\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m                         Total Parameters: 200 \u001b[0m\u001b[1;2m(800 B)\u001b[0m\u001b[1m                          \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim1 = 128\n",
    "dim2 = 32\n",
    "key = random.PRNGKey(0)\n",
    "conv = flax_CNN() #from (200,28,28) to (200, 1568)\n",
    "\n",
    "rng_key = random.PRNGKey(1)\n",
    "\n",
    "print(conv.tabulate(jax.random.PRNGKey(0), x.reshape((-1,28,28,1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "B9ZwnElxCP2Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def circ_matmul(x, w):\n",
    "    # xw = fft(fft(w)*ifft(x)).real\n",
    "    # Note the use of the n argument to get right output shape\n",
    "    xw = irfft(jnp.conj(rfft(w)) * rfft(x), n=w.shape[0])\n",
    "    return xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qmk0rGrVCQ90",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the non-linearity we use in our neural network\n",
    "def nonlin(x):\n",
    "    return jnp.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x1N4sDqtCSvJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: add numlayer parameter, add whether has cnn parameter, add whether use circulant multiply, add cnn parameters.calculate dimensions. \n",
    "\n",
    "def model_circulant_weight(x, y=None, dim1 = dim1, dim2 = dim2):\n",
    "    w1 = numpyro.sample(\"w1\", dist.Normal(0,1).expand([2*28*28]).to_event(1))\n",
    "    b1 = numpyro.sample(\"b1\", dist.Normal(0,1).expand([dim1]).to_event(1))\n",
    "\n",
    "    w2 = numpyro.sample(\"w2\", dist.Normal(0,1).expand([dim1]).to_event(1))\n",
    "    b2 = numpyro.sample(\"b2\", dist.Normal(0,1).expand([dim2]).to_event(1))\n",
    "\n",
    "\n",
    "    w3 = numpyro.sample(\"w3\", dist.Normal(0,1).expand([dim2]).to_event(2))\n",
    "    b3 = numpyro.sample(\"b3\", dist.Normal(0,1).expand([10]).to_event(1))    \n",
    "\n",
    "    # Convolution\n",
    "    conv_numpyro = module.random_flax_module(\"conv\", conv, dist.Normal(0, 1), input_shape=((x.shape[0],28,28,1)))\n",
    "    cx = nonlin(conv_numpyro(x.reshape((-1,28,28,1))))\n",
    "\n",
    "    # Layer 1: dim1\n",
    "    h1 = circ_matmul(cx, w1)\n",
    "    h1 = nonlin(h1[:, 0:dim1] + b1)\n",
    "    # Layer 2: dim2\n",
    "    h2 = circ_matmul(h1, w2)\n",
    "    h2 = nonlin(h2[:, 0:dim2] + b2)\n",
    "\n",
    "    # Layer 3: dim=10 (logits)\n",
    "    h3 = jnp.matmul(h2,w3) + b3\n",
    "    # Register the logits for easy prediction\n",
    "    numpyro.deterministic(\"logits\", h3)\n",
    "\n",
    "    # Likelihood\n",
    "    with numpyro.plate(\"labels\", x.shape[0]):\n",
    "        y_obs = numpyro.sample(\"y_obs\", dist.CategoricalLogits(logits=h3), \n",
    "                               obs=y, rng_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0b5cQ8cVKasn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_full_weight(x, y=None):\n",
    "  w1_full = numpyro.sample(\"w1_full\", dist.Normal(0,1).expand([2*28*28,dim1]).to_event(1)) #weight matrix dimension: (indim(1568), h1dim(dim1 128))\n",
    "  b1_full = numpyro.sample(\"b1_full\", dist.Normal(0,1).expand([dim1]).to_event(1)) # bias dimension: (128,)\n",
    "\n",
    "  w2_full = numpyro.sample(\"w2_full\", dist.Normal(0,1).expand([dim1,dim2]).to_event(1)) #weight matrix dimension: (h1dim(dim1), h2dim(dim2))\n",
    "  b2_full = numpyro.sample(\"b2_full\", dist.Normal(0,1).expand([dim2]).to_event(1)) # bias dimension: (dim2,)\n",
    "\n",
    "  w3_full = numpyro.sample(\"w3_full\", dist.Normal(0,1).expand([dim2,10]).to_event(2)) #weight matrix dimension: (h2dim(dim2), outdim(10))\n",
    "  b3_full = numpyro.sample(\"b3_full\", dist.Normal(0,1).expand([10]).to_event(1)) # bias dimension: (outdim(10))  \n",
    "\n",
    "  conv_numpyro = module.random_flax_module(\"conv_full\", conv, dist.Normal(0, 1), input_shape=((x.shape[0],28,28,1)))\n",
    "  cx = nonlin(conv_numpyro(x.reshape((-1,28,28,1))))\n",
    "\n",
    "\n",
    "  h1 = nonlin(jnp.matmul(cx,w1_full) + b1_full)\n",
    "\n",
    "  h2 = nonlin(jnp.matmul(h1,w2_full) + b2_full)\n",
    "\n",
    "  h3 = jnp.matmul(h2,w3_full) + b3_full\n",
    "\n",
    "  # Register the logits for easy prediction\n",
    "  numpyro.deterministic(\"logits_full\", h3)\n",
    "\n",
    "\n",
    "  # Likelihood\n",
    "  with numpyro.plate(\"labels_full\", x.shape[0]):\n",
    "      y_obs_f = numpyro.sample(\"y_obs_full\", dist.CategoricalLogits(logits = h3), obs = y, rng_key=key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The point estimate model common neural network\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=8,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "                bias = False\n",
    "            )\n",
    "        # Lift to Pyro\n",
    "        self.maxp = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Sequential(torch.nn.Linear(in_features=2*28*28, out_features=dim1), torch.nn.Tanh(), \n",
    "                                      torch.nn.Linear(in_features= dim1, out_features=dim2), torch.nn.Tanh(), \n",
    "                                      torch.nn.Linear(in_features = dim2, out_features=10), torch.nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        cx = self.conv(x)\n",
    "        px = self.maxp(cx)\n",
    "        fx = torch.flatten(px, 1)\n",
    "        x_output = self.fc(fx)\n",
    "        return x_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxaB3q9g-e0N",
    "outputId": "c44fe55c-d96d-42b9-fbb6-24b3ec331a2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the circulant matrix model\n",
    "kernel = NUTS(model_circulant_weight,\n",
    "              target_accept_prob = 0.8,\n",
    "              max_tree_depth = 10\n",
    "              )\n",
    "\n",
    "mcmc = MCMC(kernel,\n",
    "            num_samples = 100,\n",
    "            num_warmup = 50,\n",
    "            num_chains = 2,\n",
    "            progress_bar = True)\n",
    "\n",
    "mcmc.run(random.PRNGKey(0), x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKsFyO0kCUNg",
    "outputId": "5d3ba65a-016d-4747-af7c-b123fc123736"
   },
   "outputs": [],
   "source": [
    "# Train the full weight matrix model\n",
    "kernel_1 = NUTS(model_full_weight,\n",
    "              target_accept_prob = 0.8,\n",
    "              max_tree_depth = 10\n",
    "              )\n",
    "\n",
    "mcmc_1 = MCMC(kernel_1,\n",
    "            num_samples = 100,\n",
    "            num_warmup = 50,\n",
    "            num_chains = 2,\n",
    "            progress_bar = True)\n",
    "\n",
    "mcmc_1.run(random.PRNGKey(0), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [8, 1, 5, 5], but got 2-dimensional input of size [1, 784] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(point_estimate_model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[43mtrain_point_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_estimate_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 39\u001b[0m, in \u001b[0;36mtrain_point_estimation\u001b[0;34m(model, dataloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 39\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m labels \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Out: N x 2 x 28 x 28\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     cx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     px \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxp(cx)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Return N x 1568\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [8, 1, 5, 5], but got 2-dimensional input of size [1, 784] instead"
     ]
    }
   ],
   "source": [
    "# Train the point estimation mmodel\n",
    "\n",
    "def get_mnist_torch(n, m):\n",
    "    \"\"\"\n",
    "    Download MNIST and return train and evaluation sets.\n",
    "    \"\"\"\n",
    "    img_to_tensor = transforms.ToTensor()\n",
    "    mnist = datasets.MNIST('data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=img_to_tensor)\n",
    "    mnist = list(mnist)\n",
    "    # One batch with all of mnist\n",
    "    train_loader = torch.utils.data.DataLoader(mnist,\n",
    "        batch_size=len(mnist),\n",
    "        shuffle=True)\n",
    "    # x = images tensor, y = labels tensor \n",
    "    x, y = list(train_loader)[0]\n",
    "    # Flatten images\n",
    "    x = x.view(-1, 28*28)\n",
    "    # Normalize\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    # Train and test set\n",
    "    train_x, train_y = x[0:n], y[0:n]\n",
    "    val_x, val_y = x[n:n+m], y[n:n+m]\n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "\n",
    "def train_point_estimation(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    model.cuda()\n",
    "    loss_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for _, (data, label) in enumerate(dataloader):\n",
    "\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "            model.zero_grad()\n",
    "            outputs = model(data)\n",
    "            labels = label.unsqueeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        # Print the average loss at every epoch\n",
    "        average_loss = epoch_loss / (len(dataloader))\n",
    "        loss_list.append(average_loss)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Average Loss: {average_loss}')\n",
    "    return loss_list\n",
    "\n",
    "point_estimate_model = CNN()\n",
    "x_torch, y_torch, xv_torch, yv_torch = get_mnist_torch(N,M)\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(x_torch,y_torch)\n",
    "test_set = torch.utils.data.TensorDataset(xv_torch,yv_torch)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle = True, batch_size = 1)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = 1)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(point_estimate_model.parameters(), lr = 0.0001)\n",
    "\n",
    "train_point_estimation(point_estimate_model,train_loader, criterion, optimizer, 100)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "5LlrMZnPRiVt",
    "outputId": "5400cb48-112d-4147-aa98-f639b3b4dd6a"
   },
   "outputs": [],
   "source": [
    "# get posterior and prediction of the circular weight matrix model\n",
    "\n",
    "posterior_samples = mcmc.get_samples()\n",
    "\n",
    "\n",
    "posterior_predictive_test = numpyro.infer.Predictive(model_circulant_weight, posterior_samples)(\n",
    "        jax.random.PRNGKey(3),xv)\n",
    "\n",
    "posterior_predictive_train = numpyro.infer.Predictive(model_circulant_weight, posterior_samples)(\n",
    "        jax.random.PRNGKey(3),x)\n",
    "\n",
    "prior_predictive = numpyro.infer.Predictive(model_circulant_weight, num_samples=500)(\n",
    "        jax.random.PRNGKey(3),xv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aW437_KjCcBA"
   },
   "outputs": [],
   "source": [
    "# get posterior and prediction of the full weight matrix model\n",
    "\n",
    "posterior_samples_1 = mcmc_1.get_samples()\n",
    "\n",
    "\n",
    "posterior_predictive_test_1 = numpyro.infer.Predictive(model_full_weight, posterior_samples_1)(\n",
    "        jax.random.PRNGKey(3),xv)\n",
    "\n",
    "posterior_predictive_train_1 = numpyro.infer.Predictive(model_full_weight, posterior_samples_1)(\n",
    "        jax.random.PRNGKey(3),x)\n",
    "\n",
    "prior_predictive_1 = numpyro.infer.Predictive(model_full_weight, num_samples=500)(\n",
    "        jax.random.PRNGKey(3),xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(posterior_samples.keys())\n",
    "print(posterior_samples_1.keys())\n",
    "print(posterior_samples['w1'].shape)\n",
    "print(posterior_samples_1['w1_full'].shape)\n",
    "print(posterior_predictive_test_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6G-VFAvFZoFA",
    "outputId": "4198e197-74bc-437a-809a-2608d079961e"
   },
   "outputs": [],
   "source": [
    "!pip install arviz\n",
    "import arviz as az\n",
    "az.style.use(\"arviz-doc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fF-Y7a1HhiPy"
   },
   "outputs": [],
   "source": [
    "def accuracy(pred, data):\n",
    "    \"\"\"\n",
    "    Calculate accuracy of predicted labels (integers).\n",
    "\n",
    "    pred: predictions, ndarray[sample_index, chain_index, data_index, logits]\n",
    "    data: actual data (digit), ndarray[data_index]\n",
    "\n",
    "    Prediction is taken as most common predicted value.\n",
    "    Returns accuracy (#correct/#total).\n",
    "    \"\"\"\n",
    "    n=data.shape[0]\n",
    "    correct=0\n",
    "    total=0\n",
    "    for i in range(0, n):\n",
    "        # Get most common prediction value from logits\n",
    "        pred_i=int(jnp.argmax(jnp.sum(pred[:,i,:],0)))\n",
    "        # Compare prediction with data\n",
    "        if int(data[i])==int(pred_i):\n",
    "            correct+=1.0\n",
    "        total+=1.0\n",
    "    # Return fractional accuracy\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuir-trcRt5m",
    "outputId": "ead3abba-ae8b-41e0-d077-4c6500a5bba1"
   },
   "outputs": [],
   "source": [
    "# summary of circulant matrix model\n",
    "\n",
    "\n",
    "#summary_data_circulant = arviz.from_numpyro(posterior=mcmc, prior=prior_predictive, posterior_predictive= posterior_predictive_test )\n",
    "summary_data_circulant = az.convert_to_inference_data(posterior_samples)\n",
    "az.plot_ess(summary_data_circulant,var_names=['w1'], kind = 'evolution')\n",
    "plt.savefig(\"posterior_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuir-trcRt5m",
    "outputId": "ead3abba-ae8b-41e0-d077-4c6500a5bba1"
   },
   "outputs": [],
   "source": [
    "# Accuracy on test set\n",
    "logits = posterior_predictive_test['logits']\n",
    "print(\"Success posterior test = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "# Accuracy on training set\n",
    "logits = posterior_predictive_train['logits']\n",
    "print(\"Success posterior training = %.3f\" % accuracy(logits, y))\n",
    "\n",
    "logits = prior_predictive['logits']\n",
    "print(\"Success prior = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "print(\"Posterior test diagnostics:\")\n",
    "numpyro.diagnostics.print_summary(posterior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GP284gjyDB-E",
    "outputId": "79284346-f872-4cb6-f56c-e8c509f01ee9"
   },
   "outputs": [],
   "source": [
    "# summary of full weight matrix model\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy on test set\n",
    "logits = posterior_predictive_test_1['logits_full']\n",
    "\n",
    "print(\"Success posterior test = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "# Accuracy on training set\n",
    "logits = posterior_predictive_train_1['logits_full']\n",
    "print(\"Success posterior training = %.3f\" % accuracy(logits, y))\n",
    "\n",
    "logits = prior_predictive_1['logits_full']\n",
    "print(\"Success prior = %.3f\" % accuracy(logits, yv))\n",
    "\n",
    "print(\"Posterior test diagnostics:\")\n",
    "numpyro.diagnostics.print_summary(posterior_samples_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "jax:Python",
   "language": "python",
   "name": "conda-env-jax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
